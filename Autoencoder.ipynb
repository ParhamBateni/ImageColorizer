{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T20:30:07.540083400Z",
     "start_time": "2024-04-21T20:30:07.524560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from torch import arange as torch_arange\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read and Preprocess the Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1325cf4b33ea13d"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data images: 100%|██████████| 7129/7129 [00:19<00:00, 361.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data is 7129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "data_folder = os.path.join(\"data\",\"landscape Images\")\n",
    "gray_folder = os.path.join(data_folder,\"gray\")\n",
    "color_folder = os.path.join(data_folder,\"color\")\n",
    "data=[]\n",
    "for file in tqdm(set(os.listdir(gray_folder)).intersection(set(os.listdir(color_folder))),\"Reading data images\"):\n",
    "    gray_image = plt.imread(os.path.join(gray_folder,file))/255\n",
    "    color_image = plt.imread(os.path.join(color_folder,file))/255\n",
    "    data.append([file,gray_image,color_image])\n",
    "print(f\"The size of the data is {len(data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T20:50:57.969911Z",
     "start_time": "2024-04-21T20:50:38.053445Z"
    }
   },
   "id": "b7775c0a6051474"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data: 5703\n",
      "Size of test data: 1426\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "shuffle(data)\n",
    "train_data= data[:int(len(data)*(1-test_size))]\n",
    "test_data = data[int(len(data)*(1-test_size)):]\n",
    "print(f\"Size of train data: {len(train_data)}\")\n",
    "print(f\"Size of test data: {len(test_data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T20:52:59.344957Z",
     "start_time": "2024-04-21T20:52:59.313025500Z"
    }
   },
   "id": "e0f1106a2a1b0e39"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "['3380.jpg',\n array([[0.62352941, 0.62352941, 0.62352941, ..., 0.6       , 0.59215686,\n         0.58431373],\n        [0.67058824, 0.68235294, 0.6745098 , ..., 0.58039216, 0.57647059,\n         0.57254902],\n        [0.6627451 , 0.69019608, 0.68235294, ..., 0.58431373, 0.58431373,\n         0.58823529],\n        ...,\n        [0.10980392, 0.16078431, 0.24705882, ..., 0.89803922, 0.90196078,\n         0.90196078],\n        [0.17254902, 0.14509804, 0.00392157, ..., 0.89411765, 0.89803922,\n         0.90196078],\n        [0.18039216, 0.1372549 , 0.05490196, ..., 0.89019608, 0.89803922,\n         0.90588235]]),\n array([[[0.55294118, 0.62745098, 0.78431373],\n         [0.55294118, 0.62745098, 0.78431373],\n         [0.55294118, 0.62745098, 0.78431373],\n         ...,\n         [0.50196078, 0.61176471, 0.8       ],\n         [0.49803922, 0.6       , 0.79215686],\n         [0.49019608, 0.59215686, 0.78431373]],\n \n        [[0.6       , 0.6745098 , 0.83137255],\n         [0.61176471, 0.68627451, 0.84313725],\n         [0.60392157, 0.67843137, 0.83529412],\n         ...,\n         [0.48627451, 0.58823529, 0.78039216],\n         [0.48235294, 0.58431373, 0.77647059],\n         [0.47843137, 0.58039216, 0.77254902]],\n \n        [[0.59607843, 0.66666667, 0.82352941],\n         [0.62352941, 0.69411765, 0.85098039],\n         [0.61568627, 0.68627451, 0.84313725],\n         ...,\n         [0.49411765, 0.58431373, 0.78039216],\n         [0.49803922, 0.59215686, 0.78039216],\n         [0.50588235, 0.6       , 0.78823529]],\n \n        ...,\n \n        [[0.10588235, 0.10588235, 0.1372549 ],\n         [0.16078431, 0.16470588, 0.18431373],\n         [0.23529412, 0.23921569, 0.24705882],\n         ...,\n         [0.8745098 , 0.90196078, 0.93333333],\n         [0.88627451, 0.90196078, 0.9372549 ],\n         [0.88235294, 0.89803922, 0.93333333]],\n \n        [[0.16470588, 0.16470588, 0.20392157],\n         [0.14509804, 0.14509804, 0.17647059],\n         [0.        , 0.        , 0.01568627],\n         ...,\n         [0.87058824, 0.89803922, 0.92941176],\n         [0.88235294, 0.89803922, 0.93333333],\n         [0.88627451, 0.90196078, 0.9372549 ]],\n \n        [[0.16862745, 0.16862745, 0.20784314],\n         [0.1372549 , 0.1372549 , 0.16862745],\n         [0.05098039, 0.05490196, 0.07058824],\n         ...,\n         [0.8627451 , 0.89803922, 0.9254902 ],\n         [0.88235294, 0.89803922, 0.93333333],\n         [0.89019608, 0.90588235, 0.94117647]]])]"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T20:53:59.323920Z",
     "start_time": "2024-04-21T20:53:59.292257200Z"
    }
   },
   "id": "59b4b08978350021"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Design Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f8a33ef560fb4de"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 17, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([3, 17, 136])"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ImageColorizerCNNAutoEncoder(Module):\n",
    "    def __init__(self):\n",
    "        super(ImageColorizerCNNAutoEncoder,self).__init__()\n",
    "        self.encoder = Sequential()\n",
    "        self.encoder.append(Conv2d(in_channels=1,out_channels=64,kernel_size=(3,3),padding=\"same\"))\n",
    "        self.encoder.append(ReLU())\n",
    "        self.encoder.append(Conv2d(in_channels=64,out_channels=64,kernel_size=(3,3),stride=2))\n",
    "        self.encoder.append(ReLU())\n",
    "        self.encoder.append(Conv2d(in_channels=64,out_channels=128,kernel_size=(3,3),padding=\"same\"))\n",
    "        self.encoder.append(ReLU())\n",
    "        self.encoder.append(Conv2d(in_channels=128,out_channels=128,kernel_size=(3,3),stride=2))\n",
    "        self.encoder.append(ReLU())\n",
    "        self.encoder.append(Conv2d(in_channels=128,out_channels=256,kernel_size=(3,3),padding=\"same\"))\n",
    "        self.encoder.append(ReLU())\n",
    "        self.encoder.append(Conv2d(in_channels=256,out_channels=256,kernel_size=(3,3),stride=2))\n",
    "        self.encoder.append(ReLU())\n",
    "        self.encoder.append(Conv2d(in_channels=256,out_channels=64,kernel_size=(3,3),padding=\"same\"))\n",
    "        self.encoder.append(ReLU())\n",
    "        \n",
    "        self.decoder = Sequential()\n",
    "        self.decoder.append(Upsample(scale_factor=2))\n",
    "        self.decoder.append(Conv2d(in_channels=64,out_channels=32, kernel_size=(3,3),padding=\"same\"))\n",
    "        self.decoder.append(ReLU())\n",
    "        self.decoder.append(Upsample(scale_factor=2))\n",
    "        self.decoder.append(Conv2d(in_channels=32,out_channels=16, kernel_size=(3,3),padding=\"same\"))\n",
    "        self.decoder.append(ReLU())\n",
    "        self.decoder.append(Upsample(scale_factor=2))\n",
    "        self.decoder.append(Conv2d(in_channels=16,out_channels=3, kernel_size=(3,3),padding=\"same\"))\n",
    "        self.decoder.append(Sigmoid())        \n",
    "    def forward(self,x):\n",
    "        x= torch.tensor(x,dtype=torch.float).unsqueeze(0)\n",
    "        print(self.encoder(x).shape)\n",
    "        return self.decoder(self.encoder(x))\n",
    "cnn = ImageColorizerCNNAutoEncoder()\n",
    "\n",
    "cnn(data[0][1]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:11:37.042767800Z",
     "start_time": "2024-04-21T22:11:36.932982400Z"
    }
   },
   "id": "398de97390f4e5e2"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "(150, 150)"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:12:14.886601100Z",
     "start_time": "2024-04-21T22:12:14.838942500Z"
    }
   },
   "id": "ecf1f71065ad8bc7"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageColorizerCNNAutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (13): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (2): ReLU()\n",
      "    (3): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): ReLU()\n",
      "    (6): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (7): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (8): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (7): ReLU()\n",
      "  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (11): ReLU()\n",
      "  (12): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (13): ReLU()\n",
      ")\n",
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "ReLU()\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "ReLU()\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "ReLU()\n",
      "Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Sequential(\n",
      "  (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (2): ReLU()\n",
      "  (3): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (5): ReLU()\n",
      "  (6): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  (7): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (8): Sigmoid()\n",
      ")\n",
      "Upsample(scale_factor=2.0, mode='nearest')\n",
      "Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Upsample(scale_factor=2.0, mode='nearest')\n",
      "Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Upsample(scale_factor=2.0, mode='nearest')\n",
      "Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "Sigmoid()\n"
     ]
    }
   ],
   "source": [
    "for module in cnn.modules():\n",
    "    print(module)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:07:48.509661500Z",
     "start_time": "2024-04-21T22:07:48.446389700Z"
    }
   },
   "id": "15a8c6861395166c"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 150)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imread(os.path.join(gray_folder,\"2778.jpg\")).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:02:15.522025Z",
     "start_time": "2024-04-21T21:02:15.474806400Z"
    }
   },
   "id": "d5fb4227c9de6a89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a24ae3a1d1aec73"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5703,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m criterion \u001B[38;5;241m=\u001B[39m MSELoss()\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m TensorDataset(torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m),torch\u001B[38;5;241m.\u001B[39mtensor(np\u001B[38;5;241m.\u001B[39marray([d[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m train_data])))\n\u001B[0;32m     16\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m  DataLoader(train_dataset,batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m3\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5703,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "learning_rate = 0.1\n",
    "num_epochs = 4\n",
    "batch_size = 32\n",
    "\n",
    "in_features = data[0][1].size\n",
    "out_features = data[0][2].size\n",
    "hidden_layers = []\n",
    "print('0')\n",
    "dnn = ImageColorizerDNN(in_features, out_features, hidden_layers)\n",
    "print('1')\n",
    "optimizer = torch.optim.Adam(dnn.parameters(),lr=learning_rate)\n",
    "criterion = MSELoss()\n",
    "print('2')\n",
    "train_dataset = TensorDataset(torch.tensor(np.array([d[1] for d in train_data])),torch.tensor(np.array([d[2] for d in train_data])))\n",
    "train_loader =  DataLoader(train_dataset,batch_size=batch_size)\n",
    "print('3')\n",
    "for i in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        print(len(inputs))\n",
    "        break\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T20:43:36.481498800Z",
     "start_time": "2024-04-21T20:43:24.997640700Z"
    }
   },
   "id": "210d2d6a8a27c669"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "array([11400, 12150, 15000, 16200, 16500, 16650, 16950, 18600, 19650,\n       20400, 21150, 21450, 21750, 21900, 22500])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array([len(d[1]) for d in train_data]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T20:47:07.193595700Z",
     "start_time": "2024-04-21T20:47:06.943124400Z"
    }
   },
   "id": "1a04de29be570a9c"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "22500"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1].size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T20:39:52.704448600Z",
     "start_time": "2024-04-21T20:39:52.688505900Z"
    }
   },
   "id": "f32f5ef07cf2247f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7b658c9f01c07b7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
